{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1q8NY9AiOeqZPGs3SuwnqVqoojwFkCtmT","authorship_tag":"ABX9TyMlYQ4Uh1MNOFSQHEnerS2Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Train Data Loading ..."],"metadata":{"id":"4OYlDMaY8ylp"}},{"cell_type":"code","source":["import pandas as pd\n","from posixpath import sep\n","data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.txt\",sep=\"\\t+\" , header = None)\n","dataTest1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.txt\",sep=\"\\t+\" , header = None)\n","dataTest2 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dev.txt\",sep=\"\\t+\" , header = None)\n","column_names = [\"ID\", \"Turn1\", \"Turn2\", \"Turn3\" , \"Label\" ]\n","data.columns = column_names\n","data['Conversation'] = data['Turn1'] + \" \" + data[\"Turn2\"] + \" \" + data[\"Turn3\"]\n","dataTest1.columns = column_names\n","dataTest1['Conversation'] = dataTest1['Turn1'] + \" \" + dataTest1[\"Turn2\"] + \" \" + dataTest1[\"Turn3\"]\n","dataTest2.columns = column_names\n","dataTest2['Conversation'] = dataTest2['Turn1'] + \" \" + dataTest2[\"Turn2\"] + \" \" + dataTest2[\"Turn3\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ot0B1ploCZPT","executionInfo":{"status":"ok","timestamp":1704029802257,"user_tz":-360,"elapsed":3394,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"208ca794-5074-4e04-8541-4f28685cda45"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-fbc3ae9e4ee7>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.txt\",sep=\"\\t+\" , header = None)\n","<ipython-input-1-fbc3ae9e4ee7>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  dataTest1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.txt\",sep=\"\\t+\" , header = None)\n","<ipython-input-1-fbc3ae9e4ee7>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  dataTest2 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dev.txt\",sep=\"\\t+\" , header = None)\n"]}]},{"cell_type":"markdown","source":["**Data Preprocessing  **                                                \n","**1 Converting to lowercase**"],"metadata":{"id":"cC_a5J7z7vZp"}},{"cell_type":"code","source":["data['Conversation'] = data['Conversation'].str.lower()\n","data[\"Label\"] = data[\"Label\"].str.lower()\n","dataTest1['Conversation'] = dataTest1['Conversation'].str.lower()\n","dataTest1[\"Label\"] = dataTest1[\"Label\"].str.lower()\n","dataTest2['Conversation'] = dataTest2['Conversation'].str.lower()\n","dataTest2[\"Label\"] = dataTest2[\"Label\"].str.lower()\n"],"metadata":{"id":"m_-biH1D7uiS","executionInfo":{"status":"ok","timestamp":1704029805539,"user_tz":-360,"elapsed":3,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**2 Removing Punctuation**"],"metadata":{"id":"X43kT-t_-vlS"}},{"cell_type":"code","source":["import string\n","string.punctuation\n","def remove_punctuation(txt):\n","  txt_nopunct = \"\".join([c for c in txt if c not in string.punctuation])\n","  return txt_nopunct\n","data[\"Conversation\"] = data[\"Conversation\"].apply(lambda x: remove_punctuation(x))\n","dataTest1[\"Conversation\"] = dataTest1[\"Conversation\"].apply(lambda x: remove_punctuation(x))\n","dataTest2[\"Conversation\"] = dataTest2[\"Conversation\"].apply(lambda x: remove_punctuation(x))\n"],"metadata":{"id":"lj1Bc1sc-y0h","executionInfo":{"status":"ok","timestamp":1704029807588,"user_tz":-360,"elapsed":466,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**3 Converting Emojis**"],"metadata":{"id":"ItAUxKyPBS1y"}},{"cell_type":"code","source":["!pip install emoji\n","import emoji\n","\n","def replace_emojis_with_meanings(text):\n","    return emoji.demojize(text)\n","\n","data[\"Conversation\"] = data[\"Conversation\"].apply(replace_emojis_with_meanings)\n","dataTest1[\"Conversation\"] = dataTest1[\"Conversation\"].apply(replace_emojis_with_meanings)\n","dataTest2[\"Conversation\"] = dataTest2[\"Conversation\"].apply(replace_emojis_with_meanings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0UW3DtwBWJR","executionInfo":{"status":"ok","timestamp":1704029822323,"user_tz":-360,"elapsed":12398,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"7272b0f3-897c-4655-ae6c-fb2ba6582869"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.9.0\n"]}]},{"cell_type":"markdown","source":["**4 Replacing Short Forms**"],"metadata":{"id":"OKqNM8QF8BtG"}},{"cell_type":"code","source":["!pip install contractions\n","import pandas as pd\n","import contractions\n","\n","# Function to replace short forms using contractions library\n","def replace_short_forms(text):\n","    return contractions.fix(text)\n","\n","# Apply the function to the 'text' column\n","data['Conversation'] = data['Conversation'].apply(replace_short_forms)\n","dataTest1['Conversation'] =  dataTest1['Conversation'].apply(replace_short_forms)\n","dataTest2['Conversation'] =  dataTest2['Conversation'].apply(replace_short_forms)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLseVeyw8FNE","executionInfo":{"status":"ok","timestamp":1704030122693,"user_tz":-360,"elapsed":7586,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"4213162f-d204-40ba-8e26-ede4c06f4d52"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"]}]},{"cell_type":"markdown","source":["**6 Removing digits**"],"metadata":{"id":"D92oJoFD2OZA"}},{"cell_type":"code","source":["data['Conversation'] = data['Conversation'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n","dataTest1['Conversation'] = dataTest1['Conversation'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n","dataTest2['Conversation'] = dataTest2['Conversation'].replace(to_replace=r'[^\\w\\s]', value='', regex=True)"],"metadata":{"id":"lkh8M8Yp2SZ3","executionInfo":{"status":"ok","timestamp":1704030126869,"user_tz":-360,"elapsed":466,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["column_values = data['Conversation'].values\n","column_values = data['Conversation'].to_numpy()\n","label_array = data[\"Label\"].values\n","label_array = data[\"Label\"].to_numpy()\n","column_values_test1 = dataTest1['Conversation'].values\n","column_values_test1 = dataTest1['Conversation'].to_numpy()\n","label_array_test1 = dataTest1[\"Label\"].values\n","label_array_test1 = dataTest1[\"Label\"].to_numpy()\n","\n","column_values_test2 = dataTest2['Conversation'].values\n","column_values_test2 = dataTest2['Conversation'].to_numpy()\n","label_array_test2 = dataTest2[\"Label\"].values\n","label_array_test2 = dataTest2[\"Label\"].to_numpy()"],"metadata":{"id":"FnBX2Cq0Cg4i","executionInfo":{"status":"ok","timestamp":1704030128350,"user_tz":-360,"elapsed":2,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Import Section\n","import csv\n","import codecs\n","import sys\n","import io\n","import numpy as np"],"metadata":{"id":"xA7UUUBzC8TS","executionInfo":{"status":"ok","timestamp":1704030131206,"user_tz":-360,"elapsed":3,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!pip install ekphrasis\n","# For HashtagSegmentation\n","from ekphrasis.classes.segmenter import Segmenter\n","\n","# For Classifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","# Python script for confusion matrix creation.\n","from sklearn.metrics import *"],"metadata":{"id":"2RCLWKc-C_AB","executionInfo":{"status":"ok","timestamp":1704030149853,"user_tz":-360,"elapsed":16817,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5926f10-9eab-4167-dd5a-c12be67c0241"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ekphrasis\n","  Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (4.66.1)\n","Collecting colorama (from ekphrasis)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting ujson (from ekphrasis)\n","  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (3.7.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (3.8.1)\n","Collecting ftfy (from ekphrasis)\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (1.23.5)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->ekphrasis) (0.2.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->ekphrasis) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->ekphrasis) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->ekphrasis) (2023.6.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.16.0)\n","Installing collected packages: ujson, ftfy, colorama, ekphrasis\n","Successfully installed colorama-0.4.6 ekphrasis-0.5.4 ftfy-6.1.3 ujson-5.9.0\n"]}]},{"cell_type":"markdown","source":[" **Multinomial Naive Bayes **\n"],"metadata":{"id":"-9YoC558IZ0p"}},{"cell_type":"code","source":["\n","\n","def main():\n","  Conversations = []\n","  label = []\n","  l = len(label_array)\n","  for i in range (1,l) :\n","    Conversations.append(column_values[i])\n","    label.append(label_array[i])\n","    #Conversations.append(data['Conversation'][i])\n","    #label.append(label_array[i])\n","\n","  X_train = np.array(Conversations)\n","  Y_train = np.array(label)\n","\n","\n","  ########For Multinomial Naive Bayes:########\n","  from sklearn.svm import LinearSVC\n","  from sklearn.svm import SVC\n","\n","  from sklearn.naive_bayes import MultinomialNB\n","  classifier = Pipeline([\n","     ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),\n","      ('tfidf', TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)),\n","     ('clf', OneVsRestClassifier(MultinomialNB()))])\n","\n","\n","  ## Train Classifier\n","  classifier.fit(X_train, Y_train)\n","\n","  testTConversations = []\n","  testLabel = []\n","  l = len(column_values_test1)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test1[i])\n","    testLabel.append(label_array_test1[i])\n","\n","  l = len(column_values_test2)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test2[i])\n","    testLabel.append(label_array_test2[i])\n","\n","  X_test = np.array(testTConversations)\n","  testLabelPredicted = classifier.predict(X_test)\n","\n","  # Evaluation\n","  results = confusion_matrix(testLabel, testLabelPredicted)\n","\n","  print ('Confusion Matrix :')\n","  print (results)\n","\n","  #print ('Recall Score :',recall_score(testLabel, testLabelPredicted))\n","  #print ('Precision Score :',precision_score(testLabel, testLabelPredicted))\n","  print ('Macro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='macro'))\n","  print ('Micro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='micro'))\n","  print ('Weighted Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='weighted'))\n","  print ('Accuracy :',accuracy_score(testLabel, testLabelPredicted))\n","\n","  #print_confusion_matrix(results,[\"Happy\",\"Sad\",\"Angry\",\"Others\"])\n","\n","  print ('Evaluation Report : ')\n","  print (classification_report(testLabel, testLabelPredicted))\n","\n","if __name__ == '__main__':\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53L3Dvl0Di4K","executionInfo":{"status":"ok","timestamp":1704030156530,"user_tz":-360,"elapsed":3366,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"ce1df8f3-a888-48e3-bec8-6524cb2a9d8c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix :\n","[[ 142    0  302    4]\n"," [   0   36  390    0]\n"," [  26    9 6960   20]\n"," [   5    0  298   72]]\n","Macro Avg. F1 Score : 0.46152400395463433\n","Micro Avg. F1 Score : 0.8724588576960309\n","Weighted Avg. F1 Score : 0.8361324403952834\n","Accuracy : 0.8724588576960309\n","Evaluation Report : \n","              precision    recall  f1-score   support\n","\n","       angry       0.82      0.32      0.46       448\n","       happy       0.80      0.08      0.15       426\n","      others       0.88      0.99      0.93      7015\n","         sad       0.75      0.19      0.31       375\n","\n","    accuracy                           0.87      8264\n","   macro avg       0.81      0.40      0.46      8264\n","weighted avg       0.86      0.87      0.84      8264\n","\n"]}]},{"cell_type":"markdown","source":["**Linear SVC (SVM)**"],"metadata":{"id":"balolg-dI-Kt"}},{"cell_type":"code","source":["def main():\n","  Conversations = []\n","  label = []\n","  l = len(label_array)\n","  for i in range (1,l) :\n","    Conversations.append(column_values[i])\n","    label.append(label_array[i])\n","    #Conversations.append(data['Conversation'][i])\n","    #label.append(label_array[i])\n","\n","  X_train = np.array(Conversations)\n","  Y_train = np.array(label)\n","\n","\n","  ######## For Linear SVC (SVM) ##########\n","  from sklearn.svm import LinearSVC\n","  from sklearn.svm import SVC\n","\n","  classifier = Pipeline([\n","     ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),\n","     ('tfidf', TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)),\n","     ('clf', OneVsRestClassifier(LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n","      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","      multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n","      verbose=0)))])\n","\n","\n","  ## Train Classifier\n","  classifier.fit(X_train, Y_train)\n","\n","  testTConversations = []\n","  testLabel = []\n","  l = len(column_values_test1)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test1[i])\n","    testLabel.append(label_array_test1[i])\n","\n","  l = len(column_values_test2)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test2[i])\n","    testLabel.append(label_array_test2[i])\n","\n","  X_test = np.array(testTConversations)\n","  testLabelPredicted = classifier.predict(X_test)\n","\n","  # Evaluation\n","  results = confusion_matrix(testLabel, testLabelPredicted)\n","\n","  print ('Confusion Matrix :')\n","  print (results)\n","\n","  #print ('Recall Score :',recall_score(testLabel, testLabelPredicted))\n","  #print ('Precision Score :',precision_score(testLabel, testLabelPredicted))\n","  print ('Macro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='macro'))\n","  print ('Micro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='micro'))\n","  print ('Weighted Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='weighted'))\n","  print ('Accuracy :',accuracy_score(testLabel, testLabelPredicted))\n","\n","  #print_confusion_matrix(results,[\"Happy\",\"Sad\",\"Angry\",\"Others\"])\n","\n","  print ('Evaluation Report : ')\n","  print (classification_report(testLabel, testLabelPredicted))\n","\n","if __name__ == '__main__':\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704030189812,"user_tz":-360,"elapsed":27179,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"511eb05e-6293-41dd-8dc4-146393608302","id":"q0eAnOH-JHad"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix :\n","[[ 379    4   52   13]\n"," [  12  276  129    9]\n"," [ 424  335 5970  286]\n"," [  25   10   71  269]]\n","Macro Avg. F1 Score : 0.645216630593044\n","Micro Avg. F1 Score : 0.8342207163601162\n","Weighted Avg. F1 Score : 0.8503104321471552\n","Accuracy : 0.8342207163601162\n","Evaluation Report : \n","              precision    recall  f1-score   support\n","\n","       angry       0.45      0.85      0.59       448\n","       happy       0.44      0.65      0.53       426\n","      others       0.96      0.85      0.90      7015\n","         sad       0.47      0.72      0.57       375\n","\n","    accuracy                           0.83      8264\n","   macro avg       0.58      0.77      0.65      8264\n","weighted avg       0.88      0.83      0.85      8264\n","\n"]}]},{"cell_type":"markdown","source":["**SGD Classifier**"],"metadata":{"id":"E6u_vA9gJVkm"}},{"cell_type":"code","source":["def main():\n","  Conversations = []\n","  label = []\n","  l = len(label_array)\n","  for i in range (1,l) :\n","    Conversations.append(column_values[i])\n","    label.append(label_array[i])\n","    #Conversations.append(data['Conversation'][i])\n","    #label.append(label_array[i])\n","\n","  X_train = np.array(Conversations)\n","  Y_train = np.array(label)\n","\n","\n","  ########For SGD Classifier:########\n","  from sklearn.linear_model import SGDClassifier\n","  classifier = Pipeline([\n","     ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),\n","     ('clf', OneVsRestClassifier(SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)))])\n","\n","\n","  ## Train Classifier\n","  classifier.fit(X_train, Y_train)\n","\n","  testTConversations = []\n","  testLabel = []\n","  l = len(column_values_test1)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test1[i])\n","    testLabel.append(label_array_test1[i])\n","\n","\n","  l = len(column_values_test2)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test2[i])\n","    testLabel.append(label_array_test2[i])\n","\n","  X_test = np.array(testTConversations)\n","  testLabelPredicted = classifier.predict(X_test)\n","\n","  # Evaluation\n","  results = confusion_matrix(testLabel, testLabelPredicted)\n","\n","  print ('Confusion Matrix :')\n","  print (results)\n","\n","  #print ('Recall Score :',recall_score(testLabel, testLabelPredicted))\n","  #print ('Precision Score :',precision_score(testLabel, testLabelPredicted))\n","  print ('Macro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='macro'))\n","  print ('Micro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='micro'))\n","  print ('Weighted Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='weighted'))\n","  print ('Accuracy :',accuracy_score(testLabel, testLabelPredicted))\n","\n","  #print_confusion_matrix(results,[\"Happy\",\"Sad\",\"Angry\",\"Others\"])\n","\n","  print ('Evaluation Report : ')\n","  print (classification_report(testLabel, testLabelPredicted))\n","\n","if __name__ == '__main__':\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fK8R_9bJa-M","executionInfo":{"status":"ok","timestamp":1704030210204,"user_tz":-360,"elapsed":3671,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"ed3ec5f9-a3d8-41c1-f1e6-17d16e34e994"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Confusion Matrix :\n","[[ 355    7   75   11]\n"," [  14  258  147    7]\n"," [ 395  307 6083  230]\n"," [  27   12   86  250]]\n","Macro Avg. F1 Score : 0.6410439135804686\n","Micro Avg. F1 Score : 0.840513068731849\n","Weighted Avg. F1 Score : 0.8537367715547529\n","Accuracy : 0.840513068731849\n","Evaluation Report : \n","              precision    recall  f1-score   support\n","\n","       angry       0.45      0.79      0.57       448\n","       happy       0.44      0.61      0.51       426\n","      others       0.95      0.87      0.91      7015\n","         sad       0.50      0.67      0.57       375\n","\n","    accuracy                           0.84      8264\n","   macro avg       0.59      0.73      0.64      8264\n","weighted avg       0.88      0.84      0.85      8264\n","\n"]}]},{"cell_type":"markdown","source":["**Decision Tree Classifier**"],"metadata":{"id":"EyiJfQEwJrNO"}},{"cell_type":"code","source":["def main():\n","  Conversations = []\n","  label = []\n","  l = len(label_array)\n","  for i in range (1,l) :\n","    Conversations.append(column_values[i])\n","    label.append(label_array[i])\n","    #Conversations.append(data['Conversation'][i])\n","    #label.append(label_array[i])\n","\n","  X_train = np.array(Conversations)\n","  Y_train = np.array(label)\n","\n","\n","  ########For Decision Tree Classifier:########\n","  from sklearn.tree import DecisionTreeClassifier\n","\n","  classifier = Pipeline([\n","     ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),\n","     ('clf', OneVsRestClassifier(DecisionTreeClassifier(random_state=0)))])\n","\n","\n","  ## Train Classifier\n","  classifier.fit(X_train, Y_train)\n","\n","  testTConversations = []\n","  testLabel = []\n","  l = len(column_values_test1)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test1[i])\n","    testLabel.append(label_array_test1[i])\n","\n","\n","  l = len(column_values_test2)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test2[i])\n","    testLabel.append(label_array_test2[i])\n","\n","  X_test = np.array(testTConversations)\n","  testLabelPredicted = classifier.predict(X_test)\n","\n","  # Evaluation\n","  results = confusion_matrix(testLabel, testLabelPredicted)\n","\n","  print ('Confusion Matrix :')\n","  print (results)\n","\n","  #print ('Recall Score :',recall_score(testLabel, testLabelPredicted))\n","  #print ('Precision Score :',precision_score(testLabel, testLabelPredicted))\n","  print ('Macro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='macro'))\n","  print ('Micro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='micro'))\n","  print ('Weighted Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='weighted'))\n","  print ('Accuracy :',accuracy_score(testLabel, testLabelPredicted))\n","\n","  #print_confusion_matrix(results,[\"Happy\",\"Sad\",\"Angry\",\"Others\"])\n","\n","  print ('Evaluation Report : ')\n","  print (classification_report(testLabel, testLabelPredicted))\n","\n","if __name__ == '__main__':\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Stq_4lH8J1OL","executionInfo":{"status":"ok","timestamp":1704032326981,"user_tz":-360,"elapsed":239729,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"1edcaa2f-0e83-4fc0-8da9-439e009ec226"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix :\n","[[ 284   18   82   64]\n"," [   4  227  133   62]\n"," [ 189  255 5570 1001]\n"," [  12    7   62  294]]\n","Macro Avg. F1 Score : 0.5715759449796313\n","Micro Avg. F1 Score : 0.7714181994191674\n","Weighted Avg. F1 Score : 0.8080168210927035\n","Accuracy : 0.7714181994191674\n","Evaluation Report : \n","              precision    recall  f1-score   support\n","\n","       angry       0.58      0.63      0.61       448\n","       happy       0.45      0.53      0.49       426\n","      others       0.95      0.79      0.87      7015\n","         sad       0.21      0.78      0.33       375\n","\n","    accuracy                           0.77      8264\n","   macro avg       0.55      0.69      0.57      8264\n","weighted avg       0.87      0.77      0.81      8264\n","\n"]}]},{"cell_type":"markdown","source":["**OneVsRestClassifier**"],"metadata":{"id":"pOJm9sRGg88w"}},{"cell_type":"code","source":["def main():\n","  Conversations = []\n","  label = []\n","  l = len(label_array)\n","  for i in range (1,l) :\n","    Conversations.append(column_values[i])\n","    label.append(label_array[i])\n","    #Conversations.append(data['Conversation'][i])\n","    #label.append(label_array[i])\n","\n","  X_train = np.array(Conversations)\n","  Y_train = np.array(label)\n","\n","\n","  ########For Random Forest Classifier:########\n","\n","\n","  from sklearn.ensemble import RandomForestClassifier\n","\n","  classifier = Pipeline([\n","     ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),\n","     ('clf', OneVsRestClassifier(MultinomialNB()))])\n","\n","\n","  ## Train Classifier\n","  classifier.fit(X_train, Y_train)\n","\n","  testTConversations = []\n","  testLabel = []\n","  l = len(column_values_test1)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test1[i])\n","    testLabel.append(label_array_test1[i])\n","\n","\n","  l = len(column_values_test2)\n","  for i in range (1,l) :\n","    testTConversations.append(column_values_test2[i])\n","    testLabel.append(label_array_test2[i])\n","\n","  X_test = np.array(testTConversations)\n","  testLabelPredicted = classifier.predict(X_test)\n","\n","  # Evaluation\n","  results = confusion_matrix(testLabel, testLabelPredicted)\n","\n","  print ('Confusion Matrix :')\n","  print (results)\n","\n","  #print ('Recall Score :',recall_score(testLabel, testLabelPredicted))\n","  #print ('Precision Score :',precision_score(testLabel, testLabelPredicted))\n","  print ('Macro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='macro'))\n","  print ('Micro Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='micro'))\n","  print ('Weighted Avg. F1 Score :',f1_score(testLabel, testLabelPredicted, average='weighted'))\n","  print ('Accuracy :',accuracy_score(testLabel, testLabelPredicted))\n","\n","  #print_confusion_matrix(results,[\"Happy\",\"Sad\",\"Angry\",\"Others\"])\n","\n","  print ('Evaluation Report : ')\n","  print (classification_report(testLabel, testLabelPredicted))\n","\n","if __name__ == '__main__':\n","  main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgrjjhNXg_jO","executionInfo":{"status":"ok","timestamp":1704033286980,"user_tz":-360,"elapsed":7226,"user":{"displayName":"Nayemur Rahman Nayem Nayem","userId":"15814662398300793610"}},"outputId":"23064f37-286c-4bae-bc2f-00c855b3a43e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix :\n","[[ 306    3  132    7]\n"," [  16  129  269   12]\n"," [ 337   98 6391  189]\n"," [  28    3  148  196]]\n","Macro Avg. F1 Score : 0.5874656683270233\n","Micro Avg. F1 Score : 0.8497095837366893\n","Weighted Avg. F1 Score : 0.8497575141964345\n","Accuracy : 0.8497095837366893\n","Evaluation Report : \n","              precision    recall  f1-score   support\n","\n","       angry       0.45      0.68      0.54       448\n","       happy       0.55      0.30      0.39       426\n","      others       0.92      0.91      0.92      7015\n","         sad       0.49      0.52      0.50       375\n","\n","    accuracy                           0.85      8264\n","   macro avg       0.60      0.60      0.59      8264\n","weighted avg       0.86      0.85      0.85      8264\n","\n"]}]}]}